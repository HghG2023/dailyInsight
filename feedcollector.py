import asyncio
import aiohttp
import feedparser
from datetime import datetime
from html import escape
import requests
from logger import logger
from timeFormat import format_for_web
from yamlconfig import yamlconfig  # å‡è®¾å·²å®ç°åŠ è½½ feeds.yaml / config.yaml

class FeedCollector:

    _TEST = {"test": [{
                        "url": "https://blog.google/rss/",
                        "name": "Google Blog",
                        "limit": 3
                      }]
    }
    
    def __init__(self,cfg = None):
        self.header = {"User-Agent": yamlconfig().config_yaml().get("user_agent")}
        self.daily_quote = (requests.get("https://v1.hitokoto.cn/", headers=self.header).json().get("hitokoto") 
                            or 
                            requests.get("https://api.codelife.cc/yiyan/random", headers=self.header).json().get("data").get("hitokoto")
                            or
                            "ä»Šæ—¥ç½¢å·¥~~~")   
        self.feeds_cfg = yamlconfig().feeds_yaml().get("feeds", {}) if cfg is None else cfg  
        self.claims = """
                        <hr style="border:none;border-top:1px solid #ddd;margin-top:20px;margin-bottom:20px;">
                        
                        <p style="font-size:13px; color:#666; line-height:1.6;">
                        ğŸ“ <b>ç‰ˆæƒå£°æ˜ä¸å…è´£å£°æ˜ / Copyright & Disclaimer</b><br>
                        æœ¬é‚®ä»¶å†…å®¹åŸºäºå…¬å¼€çš„ <a href="https://en.wikipedia.org/wiki/RSS" target="_blank" style="color:#1a73e8;text-decoration:none;">RSS æº</a> è‡ªåŠ¨ç”Ÿæˆï¼Œä»…å±•ç¤ºæ¥æºç½‘ç«™çš„æ ‡é¢˜ã€æ‘˜è¦ä¸åŸæ–‡é“¾æ¥ï¼Œç”¨äºå­¦ä¹ ä¸ä¿¡æ¯åˆ†äº«ã€‚<br>
                        æ‰€æœ‰æ–‡ç« åŠå†…å®¹ç‰ˆæƒå½’åŸä½œè€…åŠæ‰€å±åª’ä½“æ‰€æœ‰ï¼Œè‹¥æ¶‰åŠç‰ˆæƒé—®é¢˜ï¼Œè¯·è”ç³»ä»¥ä¾¿åŠæ—¶å¤„ç†ã€‚<br>
                        æœ¬é‚®ä»¶ä¸ä»£è¡¨ä»»ä½•åª’ä½“ç«‹åœºï¼Œä¸æ‰¿æ‹…å› å†…å®¹ä½¿ç”¨æˆ–è½¬è½½æ‰€äº§ç”Ÿçš„æ³•å¾‹è´£ä»»ã€‚<br>
                        ğŸ“¬ å¦‚æœä½ å–œæ¬¢è¿™ä»½æ¯æ—¥èµ„è®¯ï¼Œæ¬¢è¿è½¬å‘åˆ†äº«ï¼Œä½†è¯·ä¿ç•™å®Œæ•´æ¥æºè¯´æ˜ã€‚<br><br>

                        This email is generated from publicly available <a href="https://en.wikipedia.org/wiki/RSS" target="_blank" style="color:#1a73e8;text-decoration:none;">RSS feeds</a> and only includes titles, summaries, and links to the original articles for educational and informational purposes.<br>
                        All articles and content are copyrighted by the original authors and their respective media. Please contact us if any copyright concerns arise.<br>
                        This email does not represent the views of any media outlet and we assume no responsibility for any legal issues arising from the use or redistribution of its content.<br>
                        ğŸ“¬ Feel free to forward this daily digest, but please retain full source attribution.
                        </p>
                    """

    async def get_entries(self, session, feed_info: dict):
        """å¼‚æ­¥è·å–ä¸€ä¸ª feed çš„è‹¥å¹²æ¡æœ€æ–°æ–‡ç« """
        url = feed_info.get("url")
        name = feed_info.get("name", url)
        limit = feed_info.get("limit", 3)
        headers = self.header

        try:
            async with session.get(url, headers=headers, timeout=15) as resp:
                if resp.status != 200:
                    logger.warning(f"è¯·æ±‚å¤±è´¥ï¼š{url}ï¼ˆHTTP {resp.status}ï¼‰")
                    return name, []

                text = await resp.text()
                feed = feedparser.parse(text)
                results = []

                for e in feed.entries[:limit]:
                    title = str(e.get("title", "(æ— æ ‡é¢˜)")).strip()
                    link = e.get("link", "#")
                    date = e.get("published") or e.get("updated") or e.get("pubDate") or "æœªçŸ¥æ—¥æœŸ"
                    results.append({"title": title, "link": link, "date": format_for_web(date)}) # type: ignore

                feed_title = feed.feed.get("title", name) # type: ignore
                return feed_title, results

        except asyncio.TimeoutError:
            logger.error(f"è¯·æ±‚è¶…æ—¶ï¼š{url}")
        except Exception as ex:
            logger.error(f"æ— æ³•è§£æï¼š{url} - {ex}")

        return name, []

    async def collect_all(self):
        """æ ¹æ® feeds.yaml ä¸­é…ç½®å¼‚æ­¥æ”¶é›†æ‰€æœ‰ä¸»é¢˜çš„æ›´æ–°"""
        feeds_cfg = self.feeds_cfg
        all_data = {}

        async with aiohttp.ClientSession() as session:
            for topic, feed_list in feeds_cfg.items():
                if not feed_list:
                    continue
                tasks = [self.get_entries(session, f) for f in feed_list]
                results = await asyncio.gather(*tasks, return_exceptions=True)

                topic_data = []
                for r in results:
                    if isinstance(r, Exception):
                        logger.warning(f"[{topic}] æŸ feed æŠ“å–å¤±è´¥ï¼š{r}")
                        continue
                    feed_title, entries = r # type: ignore
                    topic_data.append({"feed_title": feed_title, "entries": entries})

                all_data[topic] = topic_data

        return all_data

    def generate_email_html(self, all_data):
        """ç”Ÿæˆé‚®ä»¶ HTML æ ¼å¼å†…å®¹"""
        today = datetime.now().strftime("%Y-%m-%d")
        html = [
            "<style>"
            "body { font-family: 'Segoe UI', Helvetica, Arial, sans-serif; line-height:1.6; }"
            "h2 { color:#333; }"
            "h3 { color:#2b6cb0; margin-top:1em; }"
            "a { text-decoration:none; color:#1a73e8; }"
            "a:hover { text-decoration:underline; }"
            "</style>",
            f"<h2>ğŸ“… æ¯æ—¥èµ„è®¯æ±‡æ€» - {today}</h2>",
            "<hr style='border:none;border-top:2px solid #ddd;'>"
        ]
        # ğŸ’¡ æ¯æ—¥æ ¼è¨€åŒºåŸŸï¼ˆå¦‚æœæä¾›ï¼‰
        if self.daily_quote:
            # html.append(f"<div class='quote'>ğŸ’­ æœå“¥å·æ–‡~ </div>")
            html.append(f"<div class='quote'>ğŸ’­ {self.daily_quote}</div>")

        html.append("<hr style='border:none;border-top:2px solid #ddd;'>")


        for topic, feeds in all_data.items():
            topic_title = topic.replace("_", " ").title()
            html.append(f"<h3>ğŸ“° {escape(topic_title)}</h3>")

            for fdata in feeds:
                feed_title = escape(fdata.get("feed_title", "æœªçŸ¥æ¥æº"))
                entries = fdata.get("entries", [])
                html.append(f"<p><b>{feed_title}</b></p><ul style='margin-top:0;margin-bottom:1em;'>")

                if not entries:
                    html.append(
                        f"<li>æ— æ›´æ–°</li>"
                        f"<small style='color:#666;'>({today})</small><br>"
                        )

                for e in entries:
                    title = escape(e.get("title", "æ— æ ‡é¢˜"))
                    link = escape(e.get("link", "#"))
                    date = escape(e.get("date", "æœªçŸ¥æ—¥æœŸ"))

                    html.append(
                        f"<li style='margin-bottom:6px;'>"
                        f"<a href='{link}' target='_blank'>{title}</a> "
                        f"<small style='color:#666;'>({date})</small><br>"
                        f"</li>"
                    )

                html.append("</ul>")
            html.append("<hr style='border:none;border-top:1px dashed #ccc;'>")

        html.append("<p style='font-size:0.9em;color:#999;'>Generated automatically by DailyFeedBot</p>")

        html.append(self.claims)
        return "\n".join(html)

if __name__ == "__main__":
    # print(type(FeedCollector().feeds_cfg))
    ...