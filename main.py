import asyncio
import aiohttp
import feedparser
from datetime import datetime
from logger import logger
from yaml import safe_load
from sender import Mail_sender
from logger import logger, PM
from yamlconfig import yamlconfig


class Processor:
    def __init__(self):
        self.today = datetime.now().strftime("%Y-%m-%d")

    async def get_entries(self, session, url, limit=3):
        """å¼‚æ­¥è·å–ä¸€ä¸ª feed çš„è‹¥å¹²æ¡æœ€æ–°æ–‡ç« """
        headers = {"User-Agent": yamlconfig().config_yaml()["user_agent"]}
        try:
            async with session.get(url, headers=headers, timeout=10) as resp:
                text = await resp.text()
                feed = feedparser.parse(text)
                results = []
                for e in feed.entries[:limit]:
                    title = e.get("title", "(æ— æ ‡é¢˜)")
                    link = e.get("link", "#")
                    date = e.get("published", "æœªçŸ¥æ—¥æœŸ")
                    results.append({"title": title, "link": link, "date": date})
                return feed.feed.get("title", url), results  # type: ignore
        except Exception as ex:
            logger.error(f"æ— æ³•è§£æï¼š{url} - {ex}")
            return url, []

    async def collect_all(self):
        """æ ¹æ® feeds.yaml ä¸­é…ç½®å¼‚æ­¥æ”¶é›†æ‰€æœ‰ä¸»é¢˜çš„æ›´æ–°"""
        cfg = yamlconfig()
        all_data = {}

        async with aiohttp.ClientSession() as session:
            for topic, urls in cfg.feeds_yaml()['feeds'].items():
                tasks = [self.get_entries(session, url) for url in urls]
                results = await asyncio.gather(*tasks, return_exceptions=True)

                topic_data = []
                for r in results:
                    if isinstance(r, Exception):
                        logger.warning(f"{topic} æŸ feed æŠ“å–å¤±è´¥ï¼š{r}")
                        continue
                    feed_title, entries = r # type: ignore
                    topic_data.append({"feed_title": feed_title, "entries": entries})

                all_data[topic] = topic_data
        return all_data

    def generate_email_html(self, all_data):
        """ç”Ÿæˆé‚®ä»¶ HTML æ ¼å¼å†…å®¹"""
        html = [
            f"<h2>ğŸ“… æ¯æ—¥èµ„è®¯æ±‡æ€» - {self.today}</h2>",
            "<hr>",
        ]

        for topic, feeds in all_data.items():
            html.append(f"<h3>ğŸ“° {topic}</h3>")
            for fdata in feeds:
                html.append(f"<p><b>{fdata['feed_title']}</b></p><ul>")
                for e in fdata["entries"]:
                    html.append(
                        f"<li><a href='{e['link']}'>{e['title']}</a> "
                        f"<small>ï¼ˆ{e['date']}ï¼‰</small></li>"
                    )
                html.append("</ul>")
            html.append("<hr>")

        return "\n".join(html)


async def main():
    processor = Processor()
    all_data = await processor.collect_all()
    html_content = processor.generate_email_html(all_data)

    message_info = {
        "recipient_email": "huangguo02@qq.com",
        "subject": "æ¯æ—¥èµ„è®¯æ±‡æ€»",
        "message": html_content,
    }

    try:
        Mail_sender.send_mail(messageinfo=message_info)
        logger.info("âœ… é‚®ä»¶å‘é€æˆåŠŸ")
    except Exception as ex:
        logger.error(f"ğŸ“§ é‚®ä»¶å‘é€å¤±è´¥ï¼Œå°†ä¿å­˜ä¸ºæœ¬åœ°æ–‡ä»¶ - {ex}")
        filename = PM.path.parent / "emails" / f"daily_feed_{PM.today_format()}.html"
        filename.parent.mkdir(parents=True, exist_ok=True)
        with open(filename, "w", encoding="utf-8") as f:
            f.write(html_content)
        logger.info(f"âœ… å·²ä¿å­˜æœ¬åœ°æ–‡ä»¶ï¼š{filename}")


if __name__ == "__main__":
    asyncio.run(main())

